{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246a62d9",
   "metadata": {},
   "source": [
    "# Day 2 - Document Q&A with RAG using Chroma and OpenAI/OpenRouter API\n",
    "\n",
    "Welcome to the Generative AI Course!\n",
    "\n",
    "Two big limitations of LLMs are 1) that they only \"know\" the information that they were trained on, and 2) that they have limited input context windows. A way to address both of these limitations is to use a technique called Retrieval Augmented Generation, or RAG.\n",
    "\n",
    "In this notebook you will use the OpenAI API for embeddings and OpenRouter API for generation to create a vector database, retrieve answers to questions from the database and generate a final answer. You will use [Chroma](https://docs.trychroma.com/), an open-source vector database.\n",
    "\n",
    "**Prerequisites**:\n",
    "- You need an OpenAI API key stored in the `OPENAI_API_KEY` environment variable.\n",
    "- You need an OpenRouter API key stored in the `OPENROUTER_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd234a79",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "pip install -U -q \"openai\" \"chromadb\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9491a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e59ad",
   "metadata": {},
   "source": [
    "### Set up your API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a25460",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"Please set the OPENROUTER_API_KEY environment variable.\")\n",
    "\n",
    "# OpenAI client for embeddings\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# OpenRouter client for generation\n",
    "openrouter_client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2d1fa",
   "metadata": {},
   "source": [
    "### Data\n",
    "Here is a small set of documents you will use to create an embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98180f5b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e806425f",
   "metadata": {},
   "source": [
    "## Creating the embedding database with ChromaDB\n",
    "\n",
    "Create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the OpenAI API. OpenAI's text-embedding-3-small model works well for both document and query embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad466c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class OpenAIEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    # Note: OpenAI embeddings work well for both, but we keep this for consistency\n",
    "    document_mode = True\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        # Retry logic for rate limits\n",
    "        max_retries = 3\n",
    "        retry_delay = 1\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = openai_client.embeddings.create(\n",
    "                    model=\"text-embedding-3-small\",\n",
    "                    input=input,\n",
    "                )\n",
    "                return [e.embedding for e in response.data]\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1 and (hasattr(e, 'status_code') and e.status_code in {429, 503}):\n",
    "                    time.sleep(retry_delay * (attempt + 1))\n",
    "                    continue\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3057ab",
   "metadata": {},
   "source": [
    "Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `OpenAIEmbeddingFunction` and populate the database with the documents you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad06ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"googlecardb\"\n",
    "\n",
    "embed_fn = OpenAIEmbeddingFunction()\n",
    "embed_fn.document_mode = True\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n",
    "\n",
    "# Confirm insertion\n",
    "print(f\"Document count: {db.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec94f2f",
   "metadata": {},
   "source": [
    "## Retrieval: Find relevant documents\n",
    "\n",
    "To search the Chroma database, call the `query` method. Note that you also switch to the `retrieval_query` mode of embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3988912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to query mode when generating embeddings.\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"How do you use the touchscreen to play music?\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[all_passages] = result[\"documents\"]\n",
    "\n",
    "print(\"Retrieved Passage:\")\n",
    "print(all_passages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb4e82e",
   "metadata": {},
   "source": [
    "## Augmented generation: Answer the question\n",
    "\n",
    "Now that you have found a relevant passage from the set of documents (the *retrieval* step), you can now assemble a generation prompt to have the OpenRouter API *generate* a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "\"\"\"\n",
    "\n",
    "# Add the retrieved documents to the prompt.\n",
    "for passage in all_passages:\n",
    "    passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "\n",
    "print(\"--- Generated Prompt ---\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396d0e8",
   "metadata": {},
   "source": [
    "Now use the OpenRouter API to generate an answer to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68625ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openrouter_client.chat.completions.create(\n",
    "    model=\"openai/gpt-4o-mini\",  # You can use any model available on OpenRouter\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "answer_text = response.choices[0].message.content\n",
    "\n",
    "print(\"\\n--- Model Answer ---\")\n",
    "Markdown(answer_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83fc4e6",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Congrats on building a Retrieval-Augmented Generation app!\n",
    "\n",
    "To learn more about using embeddings with OpenAI, check out the [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings).\n",
    "\n",
    "For more information about OpenRouter and available models, visit [OpenRouter Models](https://openrouter.ai/models)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
